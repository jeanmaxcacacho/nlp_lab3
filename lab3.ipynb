{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d73ec8-6641-4ac0-8c0b-3460da6b0dc6",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b81ed330-330c-4915-8ee8-67f3518cdbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee26fdb9-8906-4b5a-ab52-7b8071079e50",
   "metadata": {},
   "source": [
    "# Task 1 Create Dataset for Generative Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6844ab8-1217-43c6-b8a1-f995a0c1cd17",
   "metadata": {},
   "source": [
    "### Storing the haikus into strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb3d23a4-40ab-4ec8-926d-bddd163e1c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tranquil waters flow, Whispering secrets of time, Embraced by the night.\n",
      "Moonlight dances soft, Through branches of ancient oak, Embraced by the night.\n",
      "Serene silence reigns, Stars shimmer in the night sky, Embraced by the night.\n",
      "Shadows dance gently, Across fields of golden wheat, Embraced by the night.\n",
      "Fireflies flicker bright, Illuminating the dark, Embraced by the night.\n"
     ]
    }
   ],
   "source": [
    "haiku1 = \"Tranquil waters flow, Whispering secrets of time, Embraced by the night.\"\n",
    "haiku2 = \"Moonlight dances soft, Through branches of ancient oak, Embraced by the night.\"\n",
    "haiku3 = \"Serene silence reigns, Stars shimmer in the night sky, Embraced by the night.\"\n",
    "haiku4 = \"Shadows dance gently, Across fields of golden wheat, Embraced by the night.\"\n",
    "haiku5 = \"Fireflies flicker bright, Illuminating the dark, Embraced by the night.\"\n",
    "\n",
    "haikus = [haiku1, haiku2, haiku3, haiku4, haiku5]\n",
    "\n",
    "for haiku in haikus:\n",
    "    print(haiku)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704d105c-d25b-4041-a5a8-11ed09ad23b4",
   "metadata": {},
   "source": [
    "### Tokenize haikus into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe4aa8f0-bde1-4371-af10-450767ec7157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tranquil',\n",
       "  'waters',\n",
       "  'flow',\n",
       "  ',',\n",
       "  'whispering',\n",
       "  'secrets',\n",
       "  'of',\n",
       "  'time',\n",
       "  ',',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.'],\n",
       " ['moonlight',\n",
       "  'dances',\n",
       "  'soft',\n",
       "  ',',\n",
       "  'through',\n",
       "  'branches',\n",
       "  'of',\n",
       "  'ancient',\n",
       "  'oak',\n",
       "  ',',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.'],\n",
       " ['serene',\n",
       "  'silence',\n",
       "  'reigns',\n",
       "  ',',\n",
       "  'stars',\n",
       "  'shimmer',\n",
       "  'in',\n",
       "  'the',\n",
       "  'night',\n",
       "  'sky',\n",
       "  ',',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.'],\n",
       " ['shadows',\n",
       "  'dance',\n",
       "  'gently',\n",
       "  ',',\n",
       "  'across',\n",
       "  'fields',\n",
       "  'of',\n",
       "  'golden',\n",
       "  'wheat',\n",
       "  ',',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.'],\n",
       " ['fireflies',\n",
       "  'flicker',\n",
       "  'bright',\n",
       "  ',',\n",
       "  'illuminating',\n",
       "  'the',\n",
       "  'dark',\n",
       "  ',',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\")\n",
    "\n",
    "tokenized_haikus = [tokenizer(haiku) for haiku in haikus]\n",
    "tokenized_haikus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28c67ba-942e-4a5c-9df7-0f5171e3f5b4",
   "metadata": {},
   "source": [
    "### Tagging end of line with `</l>` and end of haiku with `</e>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87d301a-ed58-4028-a088-8c4ef253aba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tranquil',\n",
       "  'waters',\n",
       "  'flow',\n",
       "  ',</l>',\n",
       "  'whispering',\n",
       "  'secrets',\n",
       "  'of',\n",
       "  'time',\n",
       "  ',</l>',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.</e>'],\n",
       " ['moonlight',\n",
       "  'dances',\n",
       "  'soft',\n",
       "  ',</l>',\n",
       "  'through',\n",
       "  'branches',\n",
       "  'of',\n",
       "  'ancient',\n",
       "  'oak',\n",
       "  ',</l>',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.</e>'],\n",
       " ['serene',\n",
       "  'silence',\n",
       "  'reigns',\n",
       "  ',</l>',\n",
       "  'stars',\n",
       "  'shimmer',\n",
       "  'in',\n",
       "  'the',\n",
       "  'night',\n",
       "  'sky',\n",
       "  ',</l>',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.</e>'],\n",
       " ['shadows',\n",
       "  'dance',\n",
       "  'gently',\n",
       "  ',</l>',\n",
       "  'across',\n",
       "  'fields',\n",
       "  'of',\n",
       "  'golden',\n",
       "  'wheat',\n",
       "  ',</l>',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.</e>'],\n",
       " ['fireflies',\n",
       "  'flicker',\n",
       "  'bright',\n",
       "  ',</l>',\n",
       "  'illuminating',\n",
       "  'the',\n",
       "  'dark',\n",
       "  ',</l>',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.</e>']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for haiku_tokens in tokenized_haikus:\n",
    "    for i, token in enumerate(haiku_tokens):\n",
    "        if token.endswith(','):\n",
    "            haiku_tokens[i] += \"</l>\"\n",
    "        elif token.endswith('.'):\n",
    "            haiku_tokens[i] += \"</e>\"\n",
    "\n",
    "tokenized_haikus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd19a64-4780-45d9-9bcb-94a782681b1b",
   "metadata": {},
   "source": [
    "### Flattening `tokenized_haikus` in place to build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26543ce-f37a-4a5a-9723-20d604a646d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tranquil',\n",
       " 'waters',\n",
       " 'flow',\n",
       " ',</l>',\n",
       " 'whispering',\n",
       " 'secrets',\n",
       " 'of',\n",
       " 'time',\n",
       " ',</l>',\n",
       " 'embraced',\n",
       " 'by',\n",
       " 'the',\n",
       " 'night',\n",
       " '.</e>',\n",
       " 'moonlight',\n",
       " 'dances',\n",
       " 'soft',\n",
       " ',</l>',\n",
       " 'through',\n",
       " 'branches',\n",
       " 'of',\n",
       " 'ancient',\n",
       " 'oak',\n",
       " ',</l>',\n",
       " 'embraced',\n",
       " 'by',\n",
       " 'the',\n",
       " 'night',\n",
       " '.</e>',\n",
       " 'serene',\n",
       " 'silence',\n",
       " 'reigns',\n",
       " ',</l>',\n",
       " 'stars',\n",
       " 'shimmer',\n",
       " 'in',\n",
       " 'the',\n",
       " 'night',\n",
       " 'sky',\n",
       " ',</l>',\n",
       " 'embraced',\n",
       " 'by',\n",
       " 'the',\n",
       " 'night',\n",
       " '.</e>',\n",
       " 'shadows',\n",
       " 'dance',\n",
       " 'gently',\n",
       " ',</l>',\n",
       " 'across',\n",
       " 'fields',\n",
       " 'of',\n",
       " 'golden',\n",
       " 'wheat',\n",
       " ',</l>',\n",
       " 'embraced',\n",
       " 'by',\n",
       " 'the',\n",
       " 'night',\n",
       " '.</e>',\n",
       " 'fireflies',\n",
       " 'flicker',\n",
       " 'bright',\n",
       " ',</l>',\n",
       " 'illuminating',\n",
       " 'the',\n",
       " 'dark',\n",
       " ',</l>',\n",
       " 'embraced',\n",
       " 'by',\n",
       " 'the',\n",
       " 'night',\n",
       " '.</e>']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten tokenized_haikus in place\n",
    "i = 0\n",
    "while i < len(tokenized_haikus):\n",
    "    if isinstance(tokenized_haikus[i], list):\n",
    "        tokenized_haikus[i:i+1] = tokenized_haikus[i]\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "tokenized_haikus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dd98ff-cabd-4493-a50b-cda0fb6b2235",
   "metadata": {},
   "source": [
    "### Building vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca083b5-f3ca-40a4-9512-e79892fb4ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocab()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = torchtext.vocab.build_vocab_from_iterator([tokenized_haikus])\n",
    "# this is a built-in vocabulary object from torchtext, might help to lookup documentation\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb40e93-1099-4f7e-a91e-51fcc6755f6a",
   "metadata": {},
   "source": [
    "### Index of each token within `vocabulary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da407dab-752c-4d26-9efe-3709eae7af29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35,\n",
       " 36,\n",
       " 17,\n",
       " 0,\n",
       " 38,\n",
       " 25,\n",
       " 6,\n",
       " 34,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 22,\n",
       " 12,\n",
       " 31,\n",
       " 0,\n",
       " 33,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 23,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 26,\n",
       " 29,\n",
       " 24,\n",
       " 0,\n",
       " 32,\n",
       " 28,\n",
       " 21,\n",
       " 1,\n",
       " 2,\n",
       " 30,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 27,\n",
       " 11,\n",
       " 18,\n",
       " 0,\n",
       " 7,\n",
       " 14,\n",
       " 6,\n",
       " 19,\n",
       " 37,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 15,\n",
       " 16,\n",
       " 10,\n",
       " 0,\n",
       " 20,\n",
       " 1,\n",
       " 13,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_tokens = [vocabulary[token] for token in tokenized_haikus]\n",
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1be52f-d0ba-49d4-b57b-d221de7a299e",
   "metadata": {},
   "source": [
    "# Task 2 Create a Model that Implements MultiheadTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a8b003-6769-46cc-b680-fc27ceed68e0",
   "metadata": {},
   "source": [
    "### Get `torch.nn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e538c6d-8a16-439d-931f-01f5c23293be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d321ace-7ca5-4ac3-9ead-ce6314bdf305",
   "metadata": {},
   "source": [
    "### Feed to an embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "682483fd-5ba7-4441-a29d-4b527a020b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 73])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dimension = 3\n",
    "vocab_size = len(vocabulary)\n",
    "\n",
    "embedding_layer = nn.Embedding(vocab_size, embedding_dimension)\n",
    "\n",
    "input_embeddings = embedding_layer(torch.tensor(indexed_tokens))\n",
    "input_embeddings = input_embeddings.transpose(0, 1)\n",
    "\n",
    "input_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf94285-d9e0-40df-831f-4a9d2e13eb6d",
   "metadata": {},
   "source": [
    "### MultiHeadAttention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff66ec43-cb6f-4a19-9812-a3937e4e7285",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_embeddings, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = nn.MultiheadAttention(self.num_embeddings, self.num_heads)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_embeddings = x.transpose(0, 1)\n",
    "\n",
    "        output_embeddings = self.attention(\n",
    "            input_embeddings,\n",
    "            input_embeddings,\n",
    "            input_embeddings\n",
    "        )\n",
    "        \n",
    "        return output_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3716bd-c5a0-4c73-ab66-ba27a7a59552",
   "metadata": {},
   "source": [
    "### Instantiate MultiHeadAttention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "568ffa07-3fe1-4116-a61f-6a6d9b0bfa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiHeadAttention = MultiHeadAttention(embedding_dimension, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415485ed-6a36-4cdb-bb31-1dc6dcd39de6",
   "metadata": {},
   "source": [
    "### Defining Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5246083-888a-4746-986f-90db7fecc9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(embedding_dimension, len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4131cadc-0b3c-4b1e-b900-b1cc51f8a3c2",
   "metadata": {},
   "source": [
    "### Passing Into Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd2e6963-9ce7-476e-8623-b3e61e8a8fe1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x73 and 3x39)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m linear_output \u001b[38;5;241m=\u001b[39m linear_layer(MultiHeadAttention\u001b[38;5;241m.\u001b[39mforward(input_embeddings)[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x73 and 3x39)"
     ]
    }
   ],
   "source": [
    "linear_output = linear_layer(MultiHeadAttention.forward(input_embeddings)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
