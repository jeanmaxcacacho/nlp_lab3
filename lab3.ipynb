{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d73ec8-6641-4ac0-8c0b-3460da6b0dc6",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b81ed330-330c-4915-8ee8-67f3518cdbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee26fdb9-8906-4b5a-ab52-7b8071079e50",
   "metadata": {},
   "source": [
    "# Task 1 Create Dataset for Generative Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6844ab8-1217-43c6-b8a1-f995a0c1cd17",
   "metadata": {},
   "source": [
    "### Storing the haikus into strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb3d23a4-40ab-4ec8-926d-bddd163e1c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tranquil waters flow, Whispering secrets of time, Embraced by the night.\n",
      "Moonlight dances soft, Through branches of ancient oak, Embraced by the night.\n",
      "Serene silence reigns, Stars shimmer in the night sky, Embraced by the night.\n",
      "Shadows dance gently, Across fields of golden wheat, Embraced by the night.\n",
      "Fireflies flicker bright, Illuminating the dark, Embraced by the night.\n"
     ]
    }
   ],
   "source": [
    "haiku1 = \"Tranquil waters flow, Whispering secrets of time, Embraced by the night.\"\n",
    "haiku2 = \"Moonlight dances soft, Through branches of ancient oak, Embraced by the night.\"\n",
    "haiku3 = \"Serene silence reigns, Stars shimmer in the night sky, Embraced by the night.\"\n",
    "haiku4 = \"Shadows dance gently, Across fields of golden wheat, Embraced by the night.\"\n",
    "haiku5 = \"Fireflies flicker bright, Illuminating the dark, Embraced by the night.\"\n",
    "\n",
    "haikus = [haiku1, haiku2, haiku3, haiku4, haiku5]\n",
    "\n",
    "for haiku in haikus:\n",
    "    print(haiku)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704d105c-d25b-4041-a5a8-11ed09ad23b4",
   "metadata": {},
   "source": [
    "### Tokenize haikus into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe4aa8f0-bde1-4371-af10-450767ec7157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tranquil',\n",
       "  'waters',\n",
       "  'flow',\n",
       "  ',',\n",
       "  'whispering',\n",
       "  'secrets',\n",
       "  'of',\n",
       "  'time',\n",
       "  ',',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.'],\n",
       " ['moonlight',\n",
       "  'dances',\n",
       "  'soft',\n",
       "  ',',\n",
       "  'through',\n",
       "  'branches',\n",
       "  'of',\n",
       "  'ancient',\n",
       "  'oak',\n",
       "  ',',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.'],\n",
       " ['serene',\n",
       "  'silence',\n",
       "  'reigns',\n",
       "  ',',\n",
       "  'stars',\n",
       "  'shimmer',\n",
       "  'in',\n",
       "  'the',\n",
       "  'night',\n",
       "  'sky',\n",
       "  ',',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.'],\n",
       " ['shadows',\n",
       "  'dance',\n",
       "  'gently',\n",
       "  ',',\n",
       "  'across',\n",
       "  'fields',\n",
       "  'of',\n",
       "  'golden',\n",
       "  'wheat',\n",
       "  ',',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.'],\n",
       " ['fireflies',\n",
       "  'flicker',\n",
       "  'bright',\n",
       "  ',',\n",
       "  'illuminating',\n",
       "  'the',\n",
       "  'dark',\n",
       "  ',',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\")\n",
    "\n",
    "tokenized_haikus = [tokenizer(haiku) for haiku in haikus]\n",
    "tokenized_haikus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6949b6a-55f3-4c54-be7d-7c71123ebfdc",
   "metadata": {},
   "source": [
    "### Generating sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b58476d4-65bd-42b4-880d-7cda3e3377fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['tranquil', 'waters', 'flow'], [',']),\n",
       " (['waters', 'flow', ','], ['whispering']),\n",
       " (['flow', ',', 'whispering'], ['secrets']),\n",
       " ([',', 'whispering', 'secrets'], ['of']),\n",
       " (['whispering', 'secrets', 'of'], ['time']),\n",
       " (['secrets', 'of', 'time'], [',']),\n",
       " (['of', 'time', ','], ['embraced']),\n",
       " (['time', ',', 'embraced'], ['by']),\n",
       " ([',', 'embraced', 'by'], ['the']),\n",
       " (['embraced', 'by', 'the'], ['night']),\n",
       " (['by', 'the', 'night'], ['.']),\n",
       " (['moonlight', 'dances', 'soft'], [',']),\n",
       " (['dances', 'soft', ','], ['through']),\n",
       " (['soft', ',', 'through'], ['branches']),\n",
       " ([',', 'through', 'branches'], ['of']),\n",
       " (['through', 'branches', 'of'], ['ancient']),\n",
       " (['branches', 'of', 'ancient'], ['oak']),\n",
       " (['of', 'ancient', 'oak'], [',']),\n",
       " (['ancient', 'oak', ','], ['embraced']),\n",
       " (['oak', ',', 'embraced'], ['by']),\n",
       " ([',', 'embraced', 'by'], ['the']),\n",
       " (['embraced', 'by', 'the'], ['night']),\n",
       " (['by', 'the', 'night'], ['.']),\n",
       " (['serene', 'silence', 'reigns'], [',']),\n",
       " (['silence', 'reigns', ','], ['stars']),\n",
       " (['reigns', ',', 'stars'], ['shimmer']),\n",
       " ([',', 'stars', 'shimmer'], ['in']),\n",
       " (['stars', 'shimmer', 'in'], ['the']),\n",
       " (['shimmer', 'in', 'the'], ['night']),\n",
       " (['in', 'the', 'night'], ['sky']),\n",
       " (['the', 'night', 'sky'], [',']),\n",
       " (['night', 'sky', ','], ['embraced']),\n",
       " (['sky', ',', 'embraced'], ['by']),\n",
       " ([',', 'embraced', 'by'], ['the']),\n",
       " (['embraced', 'by', 'the'], ['night']),\n",
       " (['by', 'the', 'night'], ['.']),\n",
       " (['shadows', 'dance', 'gently'], [',']),\n",
       " (['dance', 'gently', ','], ['across']),\n",
       " (['gently', ',', 'across'], ['fields']),\n",
       " ([',', 'across', 'fields'], ['of']),\n",
       " (['across', 'fields', 'of'], ['golden']),\n",
       " (['fields', 'of', 'golden'], ['wheat']),\n",
       " (['of', 'golden', 'wheat'], [',']),\n",
       " (['golden', 'wheat', ','], ['embraced']),\n",
       " (['wheat', ',', 'embraced'], ['by']),\n",
       " ([',', 'embraced', 'by'], ['the']),\n",
       " (['embraced', 'by', 'the'], ['night']),\n",
       " (['by', 'the', 'night'], ['.']),\n",
       " (['fireflies', 'flicker', 'bright'], [',']),\n",
       " (['flicker', 'bright', ','], ['illuminating']),\n",
       " (['bright', ',', 'illuminating'], ['the']),\n",
       " ([',', 'illuminating', 'the'], ['dark']),\n",
       " (['illuminating', 'the', 'dark'], [',']),\n",
       " (['the', 'dark', ','], ['embraced']),\n",
       " (['dark', ',', 'embraced'], ['by']),\n",
       " ([',', 'embraced', 'by'], ['the']),\n",
       " (['embraced', 'by', 'the'], ['night']),\n",
       " (['by', 'the', 'night'], ['.'])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = []\n",
    "x = 3  # x-length sequences\n",
    "y = 1  # y-length sequences\n",
    "\n",
    "for haiku_tokens in tokenized_haikus:\n",
    "    # Generate sequences for each haiku\n",
    "    for i in range(len(haiku_tokens) - x - y + 1):\n",
    "        # Extract x and y sequences\n",
    "        x_sequence = haiku_tokens[i:i + x]\n",
    "        y_sequence = haiku_tokens[i + x:i + x + y]\n",
    "        sequences.append((x_sequence, y_sequence))\n",
    "\n",
    "# let's see what it looks like\n",
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28c67ba-942e-4a5c-9df7-0f5171e3f5b4",
   "metadata": {},
   "source": [
    "### Tagging end of line with `</l>` and end of haiku with `</e>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e87d301a-ed58-4028-a088-8c4ef253aba7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(x_seq):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m token:\n\u001b[1;32m----> 4\u001b[0m         x_sequences[i][j] \u001b[38;5;241m=\u001b[39m token\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m</l>,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m token:\n\u001b[0;32m      6\u001b[0m         x_sequences[i][j] \u001b[38;5;241m=\u001b[39m token\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m</l>.</e>\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "for i, x_seq in enumerate(x_sequences):\n",
    "    for j, token in enumerate(x_seq):\n",
    "        if ',' in token:\n",
    "            x_sequences[i][j] = token.replace(',', '</l>,')\n",
    "        elif '.' in token:\n",
    "            x_sequences[i][j] = token.replace('.', '</l>.</e>')\n",
    "    # Concatenate into a single string\n",
    "    x_sequences[i] = ' '.join(x_sequences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392f072e-0b74-4c43-b235-edfd73516c11",
   "metadata": {},
   "source": [
    "### Defining fields (using torchtext classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a24f3-7bfc-4f4f-885a-d0fec1590450",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(tokenize=lambda x: x.split(), lower=True)\n",
    "LABEL = Field(sequential=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636605c5-03d8-48c3-9116-bf8cb88cab72",
   "metadata": {},
   "source": [
    "### Create examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd666a5a-704c-435b-b405-722d9468f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "for x, y in zip(x_sequences, y_sequences):\n",
    "    examples.append((x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e3ffe3-a0bc-4ae6-bc77-5999cec67b53",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd4f14f6-e0d8-470c-b67d-a184e0b5cc15",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEXT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fields \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, TEXT), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, LABEL)]\n\u001b[0;32m      2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m TabularDataset(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtsv\u001b[39m\u001b[38;5;124m'\u001b[39m, fields\u001b[38;5;241m=\u001b[39mfields, examples\u001b[38;5;241m=\u001b[39mexamples)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TEXT' is not defined"
     ]
    }
   ],
   "source": [
    "fields = [('x', TEXT), ('y', LABEL)]\n",
    "dataset = TabularDataset(path=None, format='tsv', fields=fields, examples=examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913b0e9c-25fc-41ac-8f7d-e6eea22086ff",
   "metadata": {},
   "source": [
    "### Build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6bc6937-c376-49ee-bfed-b393f3e14a36",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEXT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m TEXT\u001b[38;5;241m.\u001b[39mbuild_vocab(dataset)\n\u001b[0;32m      2\u001b[0m LABEL\u001b[38;5;241m.\u001b[39mbuild_vocab(dataset)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TEXT' is not defined"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(dataset)\n",
    "LABEL.build_vocab(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a6a77-109b-4b92-af6d-737e0096dba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
