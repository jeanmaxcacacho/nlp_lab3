{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7381d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (0.17.2)\n",
      "Requirement already satisfied: tqdm in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torchtext) (4.66.1)\n",
      "Requirement already satisfied: requests in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torchtext) (2.27.1)\n",
      "Requirement already satisfied: numpy in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torchtext) (1.26.4)\n",
      "Requirement already satisfied: torch==2.2.2 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torchtext) (2.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (4.10.0)\n",
      "Requirement already satisfied: jinja2 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (3.1.2)\n",
      "Requirement already satisfied: networkx in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (3.2.1)\n",
      "Requirement already satisfied: filelock in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (3.13.1)\n",
      "Requirement already satisfied: sympy in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (1.12)\n",
      "Requirement already satisfied: fsspec in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (2024.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from jinja2->torch==2.2.2->torchtext) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from requests->torchtext) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from requests->torchtext) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from requests->torchtext) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from requests->torchtext) (1.26.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from sympy->torch==2.2.2->torchtext) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c027cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: ['tranquil', 'waters', 'flow'], y: []\n",
      "x: ['waters', 'flow', ''], y: [,]\n",
      "x: ['flow', '', ','], y: [whispering]\n",
      "x: ['', ',', 'whispering'], y: [secrets]\n",
      "x: [',', 'whispering', 'secrets'], y: [of]\n",
      "x: ['whispering', 'secrets', 'of'], y: [time]\n",
      "x: ['secrets', 'of', 'time'], y: []\n",
      "x: ['of', 'time', ''], y: [,]\n",
      "x: ['time', '', ','], y: [embraced]\n",
      "x: ['', ',', 'embraced'], y: [by]\n",
      "x: [',', 'embraced', 'by'], y: [the]\n",
      "x: ['embraced', 'by', 'the'], y: [night]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from collections import defaultdict\n",
    "\n",
    "# tokenize\n",
    "haiku1 = \"Tranquil waters flow, Whispering secrets of time, Embraced by the night.\"\n",
    "haiku2 = \"Moonlight dances soft, Through branches of ancient oak, Embraced by the night.\"\n",
    "haiku3 = \"Serene silence reigns, Stars shimmer in the night sky, Embraced by the night.\"\n",
    "haiku4 = \"Shadows dance gently, Across fields of golden wheat, Embraced by the night.\"\n",
    "haiku5 = \"Fireflies flicker bright, Illuminating the dark, Embraced by the night.\"\n",
    "haikus = [haiku1, haiku2, haiku3, haiku4, haiku5]\n",
    "\n",
    "tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\")\n",
    "tokenized_haikus = [tokenizer(haiku) for haiku in haikus]\n",
    "\n",
    "adjusted_tokenized_haikus = []\n",
    "for haiku_tokens in tokenized_haikus:\n",
    "    adjusted_tokens = []\n",
    "    for token in haiku_tokens:\n",
    "        if ',' in token:\n",
    "            parts = token.split(',')\n",
    "            adjusted_tokens.extend([parts[0], ','])\n",
    "        elif '.' in token:\n",
    "            parts = token.split('.')\n",
    "            adjusted_tokens.extend([parts[0], '.'])\n",
    "        else:\n",
    "            adjusted_tokens.append(token)\n",
    "    adjusted_tokenized_haikus.append(adjusted_tokens)\n",
    "\n",
    "# vocab\n",
    "vocab = defaultdict(lambda: len(vocab))\n",
    "vocab['<unk>'] = 0  \n",
    "vocab['<pad>'] = 1  \n",
    "\n",
    "\n",
    "for haiku_tokens in adjusted_tokenized_haikus:\n",
    "    for token in haiku_tokens:\n",
    "        vocab[token]  \n",
    "\n",
    "# Ctokens \n",
    "token_ids_haikus = []\n",
    "for haiku_tokens in adjusted_tokenized_haikus:\n",
    "    token_ids = [vocab[token] for token in haiku_tokens]\n",
    "    token_ids_haikus.append(token_ids)\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "for token_ids in token_ids_haikus:\n",
    "    for i in range(len(token_ids) - 3):\n",
    "        data_x.append(token_ids[i:i+3])\n",
    "        data_y.append(token_ids[i+3])\n",
    "\n",
    "data_x = torch.tensor(data_x, dtype=torch.long)\n",
    "data_y = torch.tensor(data_y, dtype=torch.long)\n",
    "\n",
    "\n",
    "dataset = []\n",
    "for haiku_tokens in adjusted_tokenized_haikus:\n",
    "    for i in range(len(haiku_tokens) - 3):\n",
    "        x = haiku_tokens[i:i+3]\n",
    "        y = haiku_tokens[i+3]\n",
    "        dataset.append({'x': x, 'y': y})\n",
    "\n",
    "# change number 12 \n",
    "for data in dataset[:12]:\n",
    "    print(f\"x: {data['x']}, y: [{data['y']}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd64894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.987115935103534\n",
      "Epoch 2, Loss: 3.526947406873311\n",
      "Epoch 3, Loss: 3.328416060094964\n",
      "Epoch 4, Loss: 3.2907073530432296\n",
      "Epoch 5, Loss: 3.199951225764131\n",
      "Epoch 6, Loss: 3.1080526472771006\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "\n",
    "class TransformerModule(nn.Module):\n",
    "    def __init__(self, d_model=768, n_head=12, d_ffn=2048, dropout=0.1, device='cpu'):\n",
    "        super(TransformerModule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_ffn = d_ffn\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.device = device\n",
    "\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.ffn_1 = nn.Linear(d_model, d_ffn)\n",
    "        self.ffn_2 = nn.Linear(d_ffn, d_model)\n",
    "\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(d_model, n_head, dropout, batch_first=True, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1 = self.norm_1(x)  \n",
    "\n",
    "        \n",
    "        mask = torch.triu(torch.ones(x.shape[1], x.shape[1]), diagonal=1).bool().to(self.device)\n",
    "        x_1, _ = self.attention(x_1, x_1, x_1, attn_mask=mask, need_weights=False)\n",
    "\n",
    "        x_1 = self.dropout(x_1)\n",
    "        x_1 = x_1 + x\n",
    "        x_1 = self.norm_2(x_1)\n",
    "\n",
    "        x_2 = self.ffn_1(x_1)\n",
    "        x_2 = self.gelu(x_2)\n",
    "        x_2 = self.ffn_2(x_2)\n",
    "        x_2 = self.dropout(x_2)\n",
    "\n",
    "        return x_2 + x_1\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, context_size, vocab_size, d_model=768, dropout=0.1, n_block=12, device='cpu'):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.context_size = context_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.d_ffn = 2048\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.n_block = n_block\n",
    "        self.device = device\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.dec_blocks = nn.ModuleList([\n",
    "            TransformerModule(device=device) for _ in range(n_block)\n",
    "        ])\n",
    "\n",
    "        self.pe = self.gen_pe(context_size, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.ffn = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def gen_pe(self, r, c):\n",
    "        pe = torch.zeros(r, c).to(self.device)\n",
    "        for k in range(r):\n",
    "            for i in range(c):\n",
    "                if i % 2 == 0:\n",
    "                    theta = math.exp((-i/c) * math.log(10_000))\n",
    "                    pe[k, i] = math.sin(k * theta)\n",
    "                else:\n",
    "                    theta = math.exp(((1-i)/c) * math.log(10_000))\n",
    "                    pe[k, i] = math.cos(k * theta)\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        length = x.shape[1]\n",
    "        x = x + self.pe[:length]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for dec in self.dec_blocks:\n",
    "            x = dec(x)\n",
    "\n",
    "        x = self.ffn(x[:, -1])\n",
    "        return x\n",
    "\n",
    "\n",
    "# Model setup\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Transformer(context_size=3, vocab_size=len(vocab), device=device)\n",
    "model.to(device)\n",
    "\n",
    "# loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 1  #adjust\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i in range(0, len(data_x), batch_size):\n",
    "        batch_x = data_x[i:i + batch_size].to(device)\n",
    "        batch_y = data_y[i:i + batch_size].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss / len(data_x)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e572ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def generate_line(model, vocab, inv_vocab, device, seed_text, length):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         input_ids = [vocab.get(word, vocab['<unk>']) for word in seed_text]\n",
    "#         input_tensor = torch.tensor([input_ids], dtype=torch.long).to(device)\n",
    "\n",
    "\n",
    "#         for _ in range(length):\n",
    "#             output = model(input_tensor)\n",
    "#             next_token_id = output[0, -1].argmax().item()  \n",
    "#             input_ids.append(next_token_id)  \n",
    "#             input_tensor = torch.tensor([input_ids], dtype=torch.long).to(device)\n",
    "\n",
    "\n",
    "#         generated_words = [inv_vocab.get(id, '<unk>') for id in input_ids]\n",
    "#         return generated_words\n",
    "\n",
    "# def generate_haiku(model, vocab, inv_vocab, device, seed_text=None):\n",
    "#     if seed_text is None:\n",
    "#         seed_text = []  \n",
    "    \n",
    "\n",
    "#     line1 = generate_line(model, vocab, inv_vocab, device, seed_text, 5)\n",
    "#     line2 = generate_line(model, vocab, inv_vocab, device, [], 7)  \n",
    "#     line3 = generate_line(model, vocab, inv_vocab, device, [], 5)  \n",
    "\n",
    "\n",
    "#     haiku = ' '.join(line1) + '\\n' + ' '.join(line2) + '\\n' + ' '.join(line3)\n",
    "#     return haiku\n",
    "\n",
    "\n",
    "# vocab = {word: idx for idx, word in enumerate(vocab)}  \n",
    "# inv_vocab = {idx: word for word, idx in vocab.items()}  \n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# model = model.to(device)  \n",
    "\n",
    "# generated_haiku = generate_haiku(model, vocab, inv_vocab, device)\n",
    "# print(generated_haiku)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5154ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
