{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d73ec8-6641-4ac0-8c0b-3460da6b0dc6",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b332895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (0.17.2)\n",
      "Requirement already satisfied: requests in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torchtext) (2.27.1)\n",
      "Requirement already satisfied: numpy in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torchtext) (1.26.4)\n",
      "Requirement already satisfied: torch==2.2.2 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torchtext) (2.2.2)\n",
      "Requirement already satisfied: tqdm in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torchtext) (4.66.1)\n",
      "Requirement already satisfied: filelock in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (3.13.1)\n",
      "Requirement already satisfied: fsspec in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (2024.3.0)\n",
      "Requirement already satisfied: sympy in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (1.12)\n",
      "Requirement already satisfied: jinja2 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (4.10.0)\n",
      "Requirement already satisfied: networkx in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch==2.2.2->torchtext) (3.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from jinja2->torch==2.2.2->torchtext) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from requests->torchtext) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from requests->torchtext) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from requests->torchtext) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from requests->torchtext) (2022.9.24)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from sympy->torch==2.2.2->torchtext) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b81ed330-330c-4915-8ee8-67f3518cdbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee26fdb9-8906-4b5a-ab52-7b8071079e50",
   "metadata": {},
   "source": [
    "# Task 1 Create Dataset for Generative Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6844ab8-1217-43c6-b8a1-f995a0c1cd17",
   "metadata": {},
   "source": [
    "### Storing the haikus into strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb3d23a4-40ab-4ec8-926d-bddd163e1c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tranquil waters flow, Whispering secrets of time, Embraced by the night.\n",
      "Moonlight dances soft, Through branches of ancient oak, Embraced by the night.\n",
      "Serene silence reigns, Stars shimmer in the night sky, Embraced by the night.\n",
      "Shadows dance gently, Across fields of golden wheat, Embraced by the night.\n",
      "Fireflies flicker bright, Illuminating the dark, Embraced by the night.\n"
     ]
    }
   ],
   "source": [
    "haiku1 = \"Tranquil waters flow, Whispering secrets of time, Embraced by the night.\"\n",
    "haiku2 = \"Moonlight dances soft, Through branches of ancient oak, Embraced by the night.\"\n",
    "haiku3 = \"Serene silence reigns, Stars shimmer in the night sky, Embraced by the night.\"\n",
    "haiku4 = \"Shadows dance gently, Across fields of golden wheat, Embraced by the night.\"\n",
    "haiku5 = \"Fireflies flicker bright, Illuminating the dark, Embraced by the night.\"\n",
    "\n",
    "haikus = [haiku1, haiku2, haiku3, haiku4, haiku5]\n",
    "\n",
    "for haiku in haikus:\n",
    "    print(haiku)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704d105c-d25b-4041-a5a8-11ed09ad23b4",
   "metadata": {},
   "source": [
    "### Tokenize haikus into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe4aa8f0-bde1-4371-af10-450767ec7157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tranquil',\n",
       "  'waters',\n",
       "  'flow',\n",
       "  ',',\n",
       "  'whispering',\n",
       "  'secrets',\n",
       "  'of',\n",
       "  'time',\n",
       "  ',',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.'],\n",
       " ['moonlight',\n",
       "  'dances',\n",
       "  'soft',\n",
       "  ',',\n",
       "  'through',\n",
       "  'branches',\n",
       "  'of',\n",
       "  'ancient',\n",
       "  'oak',\n",
       "  ',',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.'],\n",
       " ['serene',\n",
       "  'silence',\n",
       "  'reigns',\n",
       "  ',',\n",
       "  'stars',\n",
       "  'shimmer',\n",
       "  'in',\n",
       "  'the',\n",
       "  'night',\n",
       "  'sky',\n",
       "  ',',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.'],\n",
       " ['shadows',\n",
       "  'dance',\n",
       "  'gently',\n",
       "  ',',\n",
       "  'across',\n",
       "  'fields',\n",
       "  'of',\n",
       "  'golden',\n",
       "  'wheat',\n",
       "  ',',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.'],\n",
       " ['fireflies',\n",
       "  'flicker',\n",
       "  'bright',\n",
       "  ',',\n",
       "  'illuminating',\n",
       "  'the',\n",
       "  'dark',\n",
       "  ',',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\")\n",
    "\n",
    "tokenized_haikus = [tokenizer(haiku) for haiku in haikus]\n",
    "tokenized_haikus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28c67ba-942e-4a5c-9df7-0f5171e3f5b4",
   "metadata": {},
   "source": [
    "### Tagging end of line with `</l>` and end of haiku with `</e>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e87d301a-ed58-4028-a088-8c4ef253aba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tranquil',\n",
       "  'waters',\n",
       "  'flow',\n",
       "  ',</l>',\n",
       "  'whispering',\n",
       "  'secrets',\n",
       "  'of',\n",
       "  'time',\n",
       "  ',</l>',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.</e>'],\n",
       " ['moonlight',\n",
       "  'dances',\n",
       "  'soft',\n",
       "  ',</l>',\n",
       "  'through',\n",
       "  'branches',\n",
       "  'of',\n",
       "  'ancient',\n",
       "  'oak',\n",
       "  ',</l>',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.</e>'],\n",
       " ['serene',\n",
       "  'silence',\n",
       "  'reigns',\n",
       "  ',</l>',\n",
       "  'stars',\n",
       "  'shimmer',\n",
       "  'in',\n",
       "  'the',\n",
       "  'night',\n",
       "  'sky',\n",
       "  ',</l>',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.</e>'],\n",
       " ['shadows',\n",
       "  'dance',\n",
       "  'gently',\n",
       "  ',</l>',\n",
       "  'across',\n",
       "  'fields',\n",
       "  'of',\n",
       "  'golden',\n",
       "  'wheat',\n",
       "  ',</l>',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.</e>'],\n",
       " ['fireflies',\n",
       "  'flicker',\n",
       "  'bright',\n",
       "  ',</l>',\n",
       "  'illuminating',\n",
       "  'the',\n",
       "  'dark',\n",
       "  ',</l>',\n",
       "  'embraced',\n",
       "  'by',\n",
       "  'the',\n",
       "  'night',\n",
       "  '.</e>']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for haiku_tokens in tokenized_haikus:\n",
    "    for i, token in enumerate(haiku_tokens):\n",
    "        if token.endswith(','):\n",
    "            haiku_tokens[i] += \"</l>\"\n",
    "        elif token.endswith('.'):\n",
    "            haiku_tokens[i] += \"</e>\"\n",
    "\n",
    "tokenized_haikus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd19a64-4780-45d9-9bcb-94a782681b1b",
   "metadata": {},
   "source": [
    "### Flattening `tokenized_haikus` in place to build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e26543ce-f37a-4a5a-9723-20d604a646d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tranquil',\n",
       " 'waters',\n",
       " 'flow',\n",
       " ',</l>',\n",
       " 'whispering',\n",
       " 'secrets',\n",
       " 'of',\n",
       " 'time',\n",
       " ',</l>',\n",
       " 'embraced',\n",
       " 'by',\n",
       " 'the',\n",
       " 'night',\n",
       " '.</e>',\n",
       " 'moonlight',\n",
       " 'dances',\n",
       " 'soft',\n",
       " ',</l>',\n",
       " 'through',\n",
       " 'branches',\n",
       " 'of',\n",
       " 'ancient',\n",
       " 'oak',\n",
       " ',</l>',\n",
       " 'embraced',\n",
       " 'by',\n",
       " 'the',\n",
       " 'night',\n",
       " '.</e>',\n",
       " 'serene',\n",
       " 'silence',\n",
       " 'reigns',\n",
       " ',</l>',\n",
       " 'stars',\n",
       " 'shimmer',\n",
       " 'in',\n",
       " 'the',\n",
       " 'night',\n",
       " 'sky',\n",
       " ',</l>',\n",
       " 'embraced',\n",
       " 'by',\n",
       " 'the',\n",
       " 'night',\n",
       " '.</e>',\n",
       " 'shadows',\n",
       " 'dance',\n",
       " 'gently',\n",
       " ',</l>',\n",
       " 'across',\n",
       " 'fields',\n",
       " 'of',\n",
       " 'golden',\n",
       " 'wheat',\n",
       " ',</l>',\n",
       " 'embraced',\n",
       " 'by',\n",
       " 'the',\n",
       " 'night',\n",
       " '.</e>',\n",
       " 'fireflies',\n",
       " 'flicker',\n",
       " 'bright',\n",
       " ',</l>',\n",
       " 'illuminating',\n",
       " 'the',\n",
       " 'dark',\n",
       " ',</l>',\n",
       " 'embraced',\n",
       " 'by',\n",
       " 'the',\n",
       " 'night',\n",
       " '.</e>']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten tokenized_haikus in place\n",
    "i = 0\n",
    "while i < len(tokenized_haikus):\n",
    "    if isinstance(tokenized_haikus[i], list):\n",
    "        tokenized_haikus[i:i+1] = tokenized_haikus[i]\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "tokenized_haikus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dd98ff-cabd-4493-a50b-cda0fb6b2235",
   "metadata": {},
   "source": [
    "### Building vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca083b5-f3ca-40a4-9512-e79892fb4ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocab()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = torchtext.vocab.build_vocab_from_iterator([tokenized_haikus])\n",
    "# this is a built-in vocabulary object from torchtext, might help to lookup documentation\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb40e93-1099-4f7e-a91e-51fcc6755f6a",
   "metadata": {},
   "source": [
    "### Index of each token within `vocabulary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da407dab-752c-4d26-9efe-3709eae7af29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35,\n",
       " 36,\n",
       " 17,\n",
       " 0,\n",
       " 38,\n",
       " 25,\n",
       " 6,\n",
       " 34,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 22,\n",
       " 12,\n",
       " 31,\n",
       " 0,\n",
       " 33,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 23,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 26,\n",
       " 29,\n",
       " 24,\n",
       " 0,\n",
       " 32,\n",
       " 28,\n",
       " 21,\n",
       " 1,\n",
       " 2,\n",
       " 30,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 27,\n",
       " 11,\n",
       " 18,\n",
       " 0,\n",
       " 7,\n",
       " 14,\n",
       " 6,\n",
       " 19,\n",
       " 37,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 15,\n",
       " 16,\n",
       " 10,\n",
       " 0,\n",
       " 20,\n",
       " 1,\n",
       " 13,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_tokens = [vocabulary[token] for token in tokenized_haikus]\n",
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1be52f-d0ba-49d4-b57b-d221de7a299e",
   "metadata": {},
   "source": [
    "# Task 2 Create a Model that Implements MultiheadTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a8b003-6769-46cc-b680-fc27ceed68e0",
   "metadata": {},
   "source": [
    "### Get `torch.nn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e538c6d-8a16-439d-931f-01f5c23293be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d321ace-7ca5-4ac3-9ead-ce6314bdf305",
   "metadata": {},
   "source": [
    "### Feed to an embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "682483fd-5ba7-4441-a29d-4b527a020b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 73])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dimension = 3\n",
    "vocab_size = len(vocabulary)\n",
    "\n",
    "embedding_layer = nn.Embedding(vocab_size, embedding_dimension)\n",
    "\n",
    "input_embeddings = embedding_layer(torch.tensor(indexed_tokens))\n",
    "input_embeddings = input_embeddings.transpose(0, 1)\n",
    "\n",
    "input_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf94285-d9e0-40df-831f-4a9d2e13eb6d",
   "metadata": {},
   "source": [
    "### MultiHeadAttention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff66ec43-cb6f-4a19-9812-a3937e4e7285",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_embeddings, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = nn.MultiheadAttention(self.num_embeddings, self.num_heads)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_embeddings = x.transpose(0, 1)\n",
    "\n",
    "        output_embeddings = self.attention(\n",
    "            input_embeddings,\n",
    "            input_embeddings,\n",
    "            input_embeddings\n",
    "        )\n",
    "        \n",
    "        return output_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3716bd-c5a0-4c73-ab66-ba27a7a59552",
   "metadata": {},
   "source": [
    "### Instantiate MultiHeadAttention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "568ffa07-3fe1-4116-a61f-6a6d9b0bfa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiHeadAttention = MultiHeadAttention(embedding_dimension, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415485ed-6a36-4cdb-bb31-1dc6dcd39de6",
   "metadata": {},
   "source": [
    "### Defining Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5246083-888a-4746-986f-90db7fecc9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(embedding_dimension, len(indexed_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4131cadc-0b3c-4b1e-b900-b1cc51f8a3c2",
   "metadata": {},
   "source": [
    "### Passing Into Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd2e6963-9ce7-476e-8623-b3e61e8a8fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5464,  0.0793, -0.4347,  ..., -0.2016,  0.5659,  0.0045],\n",
       "        [ 0.5794,  0.1398, -0.4425,  ..., -0.1636,  0.6198, -0.0731],\n",
       "        [ 0.3852,  0.0582, -0.4574,  ..., -0.3079,  0.4541,  0.1871],\n",
       "        ...,\n",
       "        [ 0.4311,  0.1274, -0.4646,  ..., -0.2597,  0.5208,  0.0888],\n",
       "        [ 0.5986,  0.1100, -0.4334,  ..., -0.1594,  0.6153, -0.0688],\n",
       "        [ 0.4398,  0.1634, -0.4712,  ..., -0.2437,  0.5461,  0.0545]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output = linear_layer(MultiHeadAttention.forward(input_embeddings)[0])\n",
    "linear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc343642",
   "metadata": {},
   "source": [
    "# Task 3 Create a Model that Implements MultiheadTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61bff16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: jinja2 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: networkx in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch) (2024.3.0)\n",
      "Requirement already satisfied: filelock in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: tqdm in /Users/danica/Downloads/Downloads/lib/python3.9/site-packages (4.66.1)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement library-name (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for library-name\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fae4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "def get_batch_loader(data, context_size, batch_size):\n",
    "    def closure():\n",
    "        ix = torch.randint(high=len(data) - context_size + 1, size=(batch_size,))\n",
    "        x = torch.stack([data[i:i+context_size] for i in ix])\n",
    "        return x\n",
    "    \n",
    "    return closure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd1817e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-24-2cc189119892>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [24], line 22\u001b[0;36m\u001b[0m\n\u001b[0;31m    x_1 = self.norm_1(x) # remember x for residual\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, d_model=768, n_head=12, d_ffn=2048, dropout=0.1, device='cpu'):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_ffn = d_ffn\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.device = device\n",
    "\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.ffn_1 = nn.Linear(d_model, d_ffn)\n",
    "        self.ffn_2 = nn.Linear(d_ffn, d_model)\n",
    "\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(d_model, n_head, dropout, batch_first=True, device=device)\n",
    "        def forward(self, x):\n",
    "        # x is of shape (N,L,d_model)\n",
    "\n",
    "            x_1 = self.norm_1(x) # remember x for residual\n",
    "\n",
    "        # generate mask for masked self-attention\n",
    "        mask = torch.triu(torch.ones(x.shape[1], x.shape[1]), diagonal=1).bool().to(self.device)\n",
    "\n",
    "        x_1, _ = self.attention(x_1, x_1, x_1, attn_mask=mask, need_weights=False)\n",
    "\n",
    "        x_1 = self.dropout(x_1)\n",
    "        x_1 = x_1 + x\n",
    "        x_1 = self.norm_2(x_1)\n",
    "\n",
    "        x_2 = self.ffn_1(x_1)\n",
    "        x_2 = self.gelu(x_2)\n",
    "        x_2 = self.ffn_2(x_2)\n",
    "        x_2 = self.dropout(x_2)\n",
    "\n",
    "        return x_2 + x_1\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, context_size, vocab_size, d_model=768, dropout=0.1, n_block=12, device='cpu'):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.context_size = context_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.d_ffn = 2048\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.n_block = n_block\n",
    "        self.device = device\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "    \n",
    "        self.dec_blocks = nn.ModuleList([\n",
    "            TransformerDecoder(device=device) for _ in range(n_block)\n",
    "        ])\n",
    "\n",
    "        self.pe = self.gen_pe(context_size, d_model)\n",
    "\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.ffn = nn.Linear(d_model, vocab_size)\n",
    "    \n",
    "    def gen_pe(self, r, c):\n",
    "        pe = torch.zeros(r, c).to(self.device)\n",
    "        for k in range(r):\n",
    "            for i in range(c):\n",
    "                if i % 2 == 0:\n",
    "                    # theta = k / (10_000 ** (i / c)) # overflow error, fixed using log-exp trick\n",
    "                    theta = math.e ** ((-i/c) * math.log(10_000))\n",
    "                    pe[k,i] = math.sin(k * theta)\n",
    "                else:\n",
    "                    # theta = k / (10_000 ** ((i-1) / c))\n",
    "                    theta = math.e ** (((-i+1)/c) * math.log(10_000))\n",
    "                    pe[k,i] = math.cos(k * theta)\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape (N,L,d_model)\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        length = x.shape[1]\n",
    "        x = x + self.pe[:length]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for dec in self.dec_blocks:\n",
    "            x = dec(x)\n",
    "        \n",
    "        x = self.ffn(x[:, -1])\n",
    "\n",
    "        # no softmax as we use CELoss\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babc8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Transformer\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd591c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
